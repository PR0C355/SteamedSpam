{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10c345de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bcc7d15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  label_num  \\\n",
      "0      Subject: enron methanol ; meter # : 988291\\r\\n...          0   \n",
      "1      Subject: hpl nom for january 9 , 2001\\r\\n( see...          0   \n",
      "2      Subject: neon retreat\\r\\nho ho ho , we ' re ar...          0   \n",
      "3      Subject: photoshop , windows , office . cheap ...          1   \n",
      "4      Subject: re : indian springs\\r\\nthis deal is t...          0   \n",
      "...                                                  ...        ...   \n",
      "19602                           :( but your not here....          0   \n",
      "19603  Becoz its  &lt;#&gt;  jan whn al the post ofic...          0   \n",
      "19604  Its a valentine game. . . send dis msg to all ...          0   \n",
      "19605                              We r outside already.          0   \n",
      "19606  The Xmas story is peace.. The Xmas msg is love...          0   \n",
      "\n",
      "      classification  \n",
      "0                ham  \n",
      "1                ham  \n",
      "2                ham  \n",
      "3       general spam  \n",
      "4                ham  \n",
      "...              ...  \n",
      "19602            ham  \n",
      "19603            ham  \n",
      "19604            ham  \n",
      "19605            ham  \n",
      "19606            ham  \n",
      "\n",
      "[19607 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"classified_spam.csv\")\n",
    "\n",
    "# Rows of interest\n",
    "print(data[[\"text\", \"label_num\", \"classification\"]])\n",
    "\n",
    "text = data[\"text\"]\n",
    "is_spam = data[\"label_num\"]\n",
    "text_class = data[\"classification\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab0c8f1",
   "metadata": {},
   "source": [
    "### Bag of Words  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1aa57a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add code for bag of words here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f99a73",
   "metadata": {},
   "source": [
    "### N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "818ec4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add code for N-grams here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f236e642",
   "metadata": {},
   "source": [
    "### Term Frequency-Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "394443cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "10fb0e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19607, 97722)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vec_X = vectorizer.fit_transform(text)\n",
    "print(vec_X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9bce5b",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "172deb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of Logistic Regression: 0.9320685434516524\n",
      "Accuracy on classifying spam: 0.6613756613756614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(vec_X, text_class, test_size=0.25, random_state=10)\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train, Y_train)\n",
    "predictions = lr.predict(X_test)\n",
    "Y_test = np.array(Y_test)\n",
    "print(\"Overall accuracy of Logistic Regression:\", sum(predictions == Y_test) / len(predictions))\n",
    "print(\"Accuracy on classifying spam:\", sum(np.where(Y_test != \"ham\", predictions == Y_test, 0)) / sum(Y_test != \"ham\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75021818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
